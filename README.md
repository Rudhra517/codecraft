# CodeCraft ğŸš€  

![GitHub stars](https://img.shields.io/github/stars/yourusername/codecraft?style=social)  
![GitHub forks](https://img.shields.io/github/forks/yourusername/codecraft?style=social)  
![GitHub repo size](https://img.shields.io/github/repo-size/yourusername/codecraft)  
![GitHub last commit](https://img.shields.io/github/last-commit/yourusername/codecraft?color=red)  
[![Discord](https://img.shields.io/badge/Discord-CodeCraft-blue?logo=discord&logoColor=white)](https://discord.gg/yourdiscord)  
[![Sponsor](https://img.shields.io/static/v1?label=Sponsor&message=%E2%9D%A4&logo=GitHub&color=%23fe8e86)](https://github.com/sponsors/yourusername)  

**CodeCraft** is an advanced **LLM training and deployment framework** that enables developers to **fine-tune, host, and interact with large language models**. The **CodeCraft model** is available on **Hugging Face** (`hf.co/rudra157/codecraft`) and can also be run locally via **Ollama**. The **frontend** is powered by **OpenWebUI**, offering a clean and interactive user interface.

---

![CodeCraft UI Demo](./demo.gif)  

## ğŸŒŸ Key Features  

- ğŸ›  **Train & Deploy Custom LLMs** â€“ Fine-tune models on domain-specific datasets.  
- âš¡ **Seamless Model Hosting** â€“ Supports **Hugging Face (Cloud)** and **Ollama (Local)**.  
- ğŸ–¥ **Intuitive Frontend** â€“ Uses **OpenWebUI** for a modern UI.  
- ğŸ“„ **Optimized for Code Generation** â€“ Fine-tuned for programming tasks.  
- ğŸ” **Secure & Flexible** â€“ Supports **Docker** and **Kubernetes** deployments.  

---

## ğŸ— Tech Stack  

| Component     | Technology |
|--------------|------------|
| **Frontend** | OpenWebUI |
| **Backend**  | Python (FastAPI/Flask) |
| **LLM Hosting** | Hugging Face, Ollama (Optional) |
| **Training Framework** | PyTorch / TensorFlow |
| **Deployment** | Docker, Kubernetes (Optional) |

---

## ğŸ“¦ Installation & Setup  

### 1ï¸âƒ£ Clone the Repository  
```bash
git clone https://github.com/yourusername/codecraft.git
cd codecraft
```

### 2ï¸âƒ£ Install Dependencies  
```bash
pip install -r requirements.txt
```

---

## ğŸ–¥ï¸ OpenWebUI Setup  

### â¤ Install OpenWebUI Locally  
```bash
git clone https://github.com/openwebui/openwebui.git
cd openwebui
docker compose up -d
```
- OpenWebUI will be available at: `http://localhost:3000`

### â¤ Run OpenWebUI with Docker  
```bash
docker run -d --name openwebui -p 3000:3000 ghcr.io/openwebui/openwebui:latest
```
- Stop OpenWebUI:  
  ```bash
  docker stop openwebui
  ```
- Restart OpenWebUI:  
  ```bash
  docker start openwebui
  ```

---

## ğŸ§  Model Inference Options  

### ğŸ”¹ **Option 1: Use CodeCraft Model from Hugging Face (Cloud)**  
1. Sign up at [Hugging Face](https://huggingface.co/)  
2. Get your API key and update `.env`:  
```env
HUGGINGFACE_API_KEY=your_api_key_here
USE_OLLAMA=False  # Set to False to use Hugging Face
```

### ğŸ”¹ **Option 2: Run CodeCraft Model Locally via Ollama**  
#### â¤ Install Ollama Locally  
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

#### â¤ Download and Run CodeCraft Model  
```bash
ollama pull hf.co/rudra157/codecraft
ollama run hf.co/rudra157/codecraft
```

#### â¤ Use Ollama in Backend (`.env` Config)  
```env
USE_OLLAMA=True
OLLAMA_MODEL=hf.co/rudra157/codecraft
```

---

## ğŸ³ **Run Ollama with Docker**  

### â¤ Pull & Run Ollama  
```bash
docker run -d --name ollama -p 11434:11434 ollama/ollama
```

### â¤ Download & Run CodeCraft Model in Ollama (Docker)  
```bash
docker exec -it ollama ollama pull hf.co/rudra157/codecraft
docker exec -it ollama ollama run hf.co/rudra157/codecraft
```

### â¤ Stop Ollama Container  
```bash
docker stop ollama
```

---

## ğŸš€ Running CodeCraft  

### â¤ Start the Backend  
```bash
python app.py
```

### â¤ Open the Web UI  
```
http://localhost:3000
```

---

## ğŸ”¥ Advanced Features  

- **Train Custom Models**: Use `train.py` for fine-tuning LLMs.  
- **API Integration**: Connect with other services via `api.py`.  
- **Multi-Model Support**: Easily switch between Hugging Face and Ollama.  
- **Docker & Kubernetes Deployment**: Run CodeCraft at scale.  

---

## ğŸ“… Roadmap  

âœ… Cloud and local inference support  
ğŸ”„ More model training optimizations  
ğŸ“ˆ Advanced analytics for LLM performance  
ğŸ”— Integration with VS Code & Jupyter  

---

## ğŸ’¡ Contributing  

We welcome contributions! Submit pull requests or open issues on GitHub.  

---

## ğŸ“ License  

This project is licensed under **MIT License**.  
